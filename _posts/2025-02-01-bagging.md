---
layout: splash
permalink: /bagging/
title: "On Bagging Models"
header:
  overlay_image: /assets/images/bagging/bagging.jpeg
excerpt: "A quick overview of boostrap aggregating models"
---

In this article we look at **bagging**, or [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating), a powerful and intuitive ensemble technique that reduces variance, enhances robustness, and improves overall predictive accuracy. This technique is particularly effective for high-variance models, such as deep decision trees, where it forms the backbone of popular algorithms like Random Forest, but it can be used with any type of method. Bagging is a special case of the ensemble averaging approach.

Instead of relying on a single model, bagging constructs an ensemble of models, each trained on a randomly sampled subset of the training data. The idea is to average the predictions of these models (for regression) or use majority voting (for classification).

Bagging does not reduce bias; it only reduces variance. It is most effective when the base models are high-variance, low-bias estimators (e.g., deep decision trees).


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
```

We will use a dataset that contains the income of several people around the world. The data is a bit old since it refers to 1994 and has 32'561 rows.


```python
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
column_names = [
    'age', 'workclass', 'fnlwgt', 'education', 'education-num',
    'marital-status', 'occupation', 'relationship', 'race', 'sex',
    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income',
]

df = pd.read_csv(url, names=column_names, sep=',\\s*', engine='python', na_values='?')
print(f"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\n")
df.sample(5)
```

    The dataset contains 32561 rows and 15 columns.
    





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26934</th>
      <td>24</td>
      <td>Local-gov</td>
      <td>452640</td>
      <td>Some-college</td>
      <td>10</td>
      <td>Never-married</td>
      <td>Tech-support</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>14344</td>
      <td>0</td>
      <td>50</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>15798</th>
      <td>40</td>
      <td>Private</td>
      <td>209833</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Never-married</td>
      <td>Craft-repair</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>29713</th>
      <td>19</td>
      <td>Local-gov</td>
      <td>243960</td>
      <td>Some-college</td>
      <td>10</td>
      <td>Never-married</td>
      <td>Sales</td>
      <td>Own-child</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>16</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>16011</th>
      <td>39</td>
      <td>Private</td>
      <td>186420</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>30899</th>
      <td>30</td>
      <td>Federal-gov</td>
      <td>127610</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>35</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>



The meaning of the columns is the following:
- *age*: discrete (from 17 to 90)
- *workclass* (private, federal-government, etc): nominal (9 categories)
- *fnlwgt*: the final weight (the number of people the census believes the entry represents): discrete
- *education* (the highest level of education obtained): ordinal (16 categories)
- *education-num* (the number of years of education): discrete (from 1 to 16)
- *marital-status*: nominal (7 categories)
- *occupation* (transport-moving, craft-repair, etc): nominal (15 categories)
- *relationship* in family (unmarried, not in the family, etc): nominal (6 categories)
- *race*: nominal (5 categories)
- *sex*: nominal (2 categories)
- *capital-gain*: continuous
- *capital-loss*: continuous
- *hours-per-week* (hours worked per week(): discrete (from 1 to 99)
- *native-country*: nominal (42 countries)
- *income* (whether or not an individual makes more than $50,000 annually): boolean (â‰¤$50k, >$50k)


```python
df = df.dropna()
print(f"# rows after removing missing values: {len(df)}")
```

    # rows after removing missing values: 30162



```python
df.describe(include='all').T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>age</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>38.581647</td>
      <td>13.640433</td>
      <td>17.0</td>
      <td>28.0</td>
      <td>37.0</td>
      <td>48.0</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>workclass</th>
      <td>30725</td>
      <td>8</td>
      <td>Private</td>
      <td>22696</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>fnlwgt</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>189778.366512</td>
      <td>105549.977697</td>
      <td>12285.0</td>
      <td>117827.0</td>
      <td>178356.0</td>
      <td>237051.0</td>
      <td>1484705.0</td>
    </tr>
    <tr>
      <th>education</th>
      <td>32561</td>
      <td>16</td>
      <td>HS-grad</td>
      <td>10501</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>education-num</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.080679</td>
      <td>2.57272</td>
      <td>1.0</td>
      <td>9.0</td>
      <td>10.0</td>
      <td>12.0</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>marital-status</th>
      <td>32561</td>
      <td>7</td>
      <td>Married-civ-spouse</td>
      <td>14976</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>occupation</th>
      <td>30718</td>
      <td>14</td>
      <td>Prof-specialty</td>
      <td>4140</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>relationship</th>
      <td>32561</td>
      <td>6</td>
      <td>Husband</td>
      <td>13193</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>race</th>
      <td>32561</td>
      <td>5</td>
      <td>White</td>
      <td>27816</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>sex</th>
      <td>32561</td>
      <td>2</td>
      <td>Male</td>
      <td>21790</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>capital-gain</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1077.648844</td>
      <td>7385.292085</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>99999.0</td>
    </tr>
    <tr>
      <th>capital-loss</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>87.30383</td>
      <td>402.960219</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4356.0</td>
    </tr>
    <tr>
      <th>hours-per-week</th>
      <td>32561.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>40.437456</td>
      <td>12.347429</td>
      <td>1.0</td>
      <td>40.0</td>
      <td>40.0</td>
      <td>45.0</td>
      <td>99.0</td>
    </tr>
    <tr>
      <th>native-country</th>
      <td>31978</td>
      <td>41</td>
      <td>United-States</td>
      <td>29170</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>income</th>
      <td>32561</td>
      <td>2</td>
      <td>&lt;=50K</td>
      <td>24720</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
education_order = [
    'Preschool',
    '1st-4th',
    '5th-6th',
    '7th-8th',
    '9th',
    '10th',
    '11th',
    '12th',
    'HS-grad',
    'Some-college',
    'Assoc-voc',
    'Assoc-acdm',
    'Bachelors',
    'Masters',
    'Prof-school',
    'Doctorate'
]
```


```python
income_proportions = pd.crosstab(df['education'], df['income'], normalize='index')
income_proportions = income_proportions.reset_index()
income_proportions = income_proportions.melt(id_vars='education', var_name='income', value_name='proportion')

# Sort by the education_levels order
income_proportions['education'] = pd.Categorical(income_proportions['education'], categories=education_order, ordered=True)
income_proportions = income_proportions.sort_values('education')

plt.figure(figsize=(12, 6))
sns.barplot(
    data=income_proportions,
    x='education',
    y='proportion',
    hue='income'
)

plt.title('Proportion of Income Levels by Education')
plt.xlabel('Education Level')
plt.ylabel('Proportion')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
```


    
![png](/assets/images/bagging/bagging-1.png)
    


As one would expect, we see from the bar graph that as the education level increase, the proportion of people who earn more than 50k a year also increase. It is interesting to note that only after a master's degree, the proportion of people earning more than 50k a year, is a majority.


```python
plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='age', hue='sex', bins=20, multiple='dodge', kde=True)
plt.title('Age Distribution', pad=20)
plt.xlabel('Age', labelpad=10)
plt.ylabel('Count', labelpad=10)
plt.tight_layout()
```


    
![png](/assets/images/bagging/bagging-2.png)
    


Distribution of income by age is as expected as well, at least for males: it grows with age, peaking around 40, then dicreases. For females it is instead decreasing from the mid-twenties, possibly because of time invested in the family. This is for 1994's societies, in today's value the peak would rather be around 50, with less distortion between males and females. Gender disparities are shown clearly in the graph below.


```python
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='sex', hue='income')
plt.title('Income Distribution by Gender')
plt.xlabel('Sex')
plt.ylabel('Count')
plt.legend(title='Income')
plt.tight_layout()
```


    
![png](/assets/images/bagging/bagging-3.png)
    


The heatmap with numerical features doesn't show any strong correlation.


```python
plt.figure(figsize=(8,5))
sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Between Features");
```


    
![png](/assets/images/bagging/bagging-4.png)
    



```python
features_to_use = [
    'age',
    'workclass',
    'education',
    'marital-status', 
    'occupation',
    'relationship',
    'race',
    'sex', 
    'capital-gain',
    'capital-loss',
    'hours-per-week',
    'native-country',
]

X = df[features_to_use].copy()

label_encoders = {}
categorical_cols = X.select_dtypes(include=['object']).columns
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

y = df['income'].copy()
y = (y == '>50K').astype(int)
print(f"# positive entries: {y.mean():.2%}, # negative entries: {(1 - y).mean():.2%}")
print(f"Final number of features (after one-hot encoding): {X.shape[1]}")
```

    # positive entries: 24.08%, # negative entries: 75.92%
    Final number of features (after one-hot encoding): 95



```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)
print(f"# train samples: {len(X_train):,}, # test samples: {len(X_test):,}")
```

    # train samples: 22,621, # test samples: 7,541



```python
single_tree = DecisionTreeClassifier(random_state=42)
single_tree.fit(X_train, y_train)

y_pred_single = single_tree.predict(X_test)
accuracy_single = accuracy_score(y_test, y_pred_single)
f1_single = f1_score(y_test, y_pred_single)

print(f"Test Accuracy: {accuracy_single:.4f} ({accuracy_single*100:.2f}%)")
print(f"F1 Score: {f1_single:.4f}")

cv_scores_single = cross_val_score(single_tree, X, y, cv=5, scoring='accuracy')
print(f"Cross-validation Accuracy: {cv_scores_single.mean():.4f} (+/- {cv_scores_single.std():.4f})")
```

    Test Accuracy: 0.8124 (81.24%)
    F1 Score: 0.6197
    Cross-validation Accuracy: 0.8147 (+/- 0.0042)



```python
bagging_clf = BaggingClassifier(
    estimator=DecisionTreeClassifier(),
    n_estimators=20,
    max_samples=0.5,
    max_features=1.0,
    bootstrap=True,
    bootstrap_features=True,
    random_state=42,
    n_jobs=-1,
)

bagging_clf.fit(X_train, y_train)

y_pred_bagging = bagging_clf.predict(X_test)
accuracy_bagging = accuracy_score(y_test, y_pred_bagging)
f1_bagging = f1_score(y_test, y_pred_bagging)

print(f"Test Accuracy: {accuracy_bagging:.4f} ({accuracy_bagging*100:.2f}%)")
print(f"F1 Score: {f1_bagging:.4f}")

cv_scores_bagging = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')
print(f"Cross-validation Accuracy: {cv_scores_bagging.mean():.4f} (+/- {cv_scores_bagging.std():.4f})")
```

    Test Accuracy: 0.8540 (85.40%)
    F1 Score: 0.6730
    Cross-validation Accuracy: 0.8574 (+/- 0.0043)

